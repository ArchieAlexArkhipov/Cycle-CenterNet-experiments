{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33marchiealexarkhipov\u001b[0m (\u001b[33mcenternet\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=17.50s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=5.16s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-08 18:23:06,726 - mmdet - INFO - Automatic scaling of learning rate (LR) has been disabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=7.12s)\n",
      "creating index...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-08 18:23:14,563 - mmdet - INFO - Start running, host: aiarhipov@lorien.atp-fivt.org, work_dir: /home/aiarhipov/centernet/exps/30_quad\n",
      "2023-06-08 18:23:14,565 - mmdet - INFO - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      "(VERY_LOW    ) TensorboardLoggerHook              \n",
      "(VERY_LOW    ) MMDetWandbHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(NORMAL      ) NumClassCheckHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      "(VERY_LOW    ) TensorboardLoggerHook              \n",
      "(VERY_LOW    ) MMDetWandbHook                     \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) EvalHook                           \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(ABOVE_NORMAL) OptimizerHook                      \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      "(VERY_LOW    ) TensorboardLoggerHook              \n",
      "(VERY_LOW    ) MMDetWandbHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      "(VERY_LOW    ) TensorboardLoggerHook              \n",
      "(VERY_LOW    ) MMDetWandbHook                     \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) NumClassCheckHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      "(VERY_LOW    ) TensorboardLoggerHook              \n",
      "(VERY_LOW    ) MMDetWandbHook                     \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      "(VERY_LOW    ) TensorboardLoggerHook              \n",
      "(VERY_LOW    ) MMDetWandbHook                     \n",
      " -------------------- \n",
      "after_run:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      "(VERY_LOW    ) TensorboardLoggerHook              \n",
      "(VERY_LOW    ) MMDetWandbHook                     \n",
      " -------------------- \n",
      "2023-06-08 18:23:14,566 - mmdet - INFO - workflow: [('train', 1), ('val', 1)], max: 1 epochs\n",
      "2023-06-08 18:23:14,567 - mmdet - INFO - Checkpoints will be saved to /home/aiarhipov/centernet/exps/30_quad by HardDiskBackend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index created!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/aiarhipov/centernet/exps/wandb/wandb/run-20230608_182314-2l0302nm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/centernet/CenterNet/runs/2l0302nm\" target=\"_blank\">30_quad</a></strong> to <a href=\"https://wandb.ai/centernet/CenterNet\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-08 18:23:19,150 - mmdet - WARNING - No meta information found in the runner. \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   12 of 12 files downloaded.  \n"
     ]
    }
   ],
   "source": [
    "import os.path as osp\n",
    "from sys import argv\n",
    "import cv2\n",
    "import mmcv\n",
    "import wandb\n",
    "from mmcv import Config\n",
    "from mmdet.apis import set_random_seed, train_detector\n",
    "\n",
    "# Let's take a look at the dataset image\n",
    "from mmdet.datasets import build_dataset\n",
    "from mmdet.models import build_detector\n",
    "import subprocess\n",
    "import random\n",
    "\n",
    "\n",
    "def get_free_gpu():\n",
    "    log = str(\n",
    "        subprocess.check_output(\"nvidia-smi --format=csv --query-gpu=utilization.gpu,memory.used\", shell=True)\n",
    "    ).split(r\"\\n\")[1:-1]\n",
    "    free_gpu = []\n",
    "    for idx, gpu_info in enumerate(log):\n",
    "        if gpu_info[:-4].split(\" %, \")[0] == \"0\" and gpu_info[:-4].split(\" %, \")[1] == \"3\":\n",
    "            free_gpu.append(idx)\n",
    "    if free_gpu:\n",
    "        return random.choice(free_gpu)\n",
    "    raise RuntimeError(\"All gpus are used\")\n",
    "\n",
    "\n",
    "wandb.login()\n",
    "\n",
    "cfg = Config.fromfile(f\"/home/aiarhipov/centernet/exps/30_quad/config.py\")\n",
    "\n",
    "\n",
    "set_random_seed(0, deterministic=False)\n",
    "cfg.gpu_ids = [get_free_gpu()]\n",
    "val = True\n",
    "# Build dataset\n",
    "\n",
    "# datasets = build_dataset(cfg.data.train)\n",
    "datasets = [build_dataset(cfg.data.train), build_dataset(cfg.data.val_loss)]\n",
    "\n",
    "# Build the detector\n",
    "model = build_detector(cfg.model)\n",
    "# Add an attribute for visualization convenience\n",
    "model.CLASSES = datasets[0].CLASSES\n",
    "\n",
    "# Create work_dir\n",
    "mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n",
    "train_detector(model, datasets, cfg, distributed=False, validate=val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m<__array_function__ internals>\u001b[0m(180)\u001b[0;36mconcatenate\u001b[0;34m()\u001b[0m\n",
      "\n",
      "> \u001b[0;32m/home/aiarhipov/mmdetection/mmdet/datasets/samplers/group_sampler.py\u001b[0m(36)\u001b[0;36m__iter__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     34 \u001b[0;31m                [indice, np.random.choice(indice, num_extra)])\n",
      "\u001b[0m\u001b[0;32m     35 \u001b[0;31m            \u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 36 \u001b[0;31m        \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     37 \u001b[0;31m        indices = [\n",
      "\u001b[0m\u001b[0;32m     38 \u001b[0;31m            \u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples_per_gpu\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples_per_gpu\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "*** NameError: name 'indice' is not defined\n",
      "[]\n",
      "> \u001b[0;32m/home/aiarhipov/miniconda3/envs/mmdet_edit/lib/python3.8/site-packages/torch/utils/data/sampler.py\u001b[0m(227)\u001b[0;36m__iter__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    225 \u001b[0;31m    \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    226 \u001b[0;31m        \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 227 \u001b[0;31m        \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    228 \u001b[0;31m            \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    229 \u001b[0;31m            \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "<mmdet.datasets.samplers.group_sampler.GroupSampler object at 0x7f2387acdee0>\n",
      "> \u001b[0;32m/home/aiarhipov/miniconda3/envs/mmdet_edit/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m(508)\u001b[0;36m_next_index\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    506 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    507 \u001b[0;31m    \u001b[0;32mdef\u001b[0m \u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 508 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    509 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    510 \u001b[0;31m    \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "> \u001b[0;32m/home/aiarhipov/miniconda3/envs/mmdet_edit/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m(1205)\u001b[0;36m_try_put_index\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m   1203 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1204 \u001b[0;31m        \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m-> 1205 \u001b[0;31m            \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1206 \u001b[0;31m        \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1207 \u001b[0;31m            \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "> \u001b[0;32m/home/aiarhipov/miniconda3/envs/mmdet_edit/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m(971)\u001b[0;36m_reset\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    969 \u001b[0;31m        \u001b[0;31m# prime the prefetch loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    970 \u001b[0;31m        \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prefetch_factor\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_workers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 971 \u001b[0;31m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    972 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    973 \u001b[0;31m    \u001b[0;32mdef\u001b[0m \u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMP_STATUS_CHECK_INTERVAL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "> \u001b[0;32m/home/aiarhipov/miniconda3/envs/mmdet_edit/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m(940)\u001b[0;36m__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    938 \u001b[0;31m        \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignal_handling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_SIGCHLD_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    939 \u001b[0;31m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_worker_pids_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 940 \u001b[0;31m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfirst_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    941 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    942 \u001b[0;31m    \u001b[0;32mdef\u001b[0m \u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfirst_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f2387adfb80>\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f2387adfb80>\n"
     ]
    }
   ],
   "source": [
    "%debug\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98.304"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[0][\"gt_masks\"].data[0].masks[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/home/aiarhipov/mmdetection/mmdet/models/utils/gaussian_target.py\u001b[0m(56)\u001b[0;36mgen_gaussian_target\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     54 \u001b[0;31m    \u001b[0mtop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbottom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mradius\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheight\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mradius\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     55 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 56 \u001b[0;31m    \u001b[0mmasked_heatmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mheatmap\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtop\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbottom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mleft\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     57 \u001b[0;31m    masked_gaussian = gaussian_kernel[radius - top:radius + bottom,\n",
      "\u001b[0m\u001b[0;32m     58 \u001b[0;31m                                      radius - left:radius + right]\n",
      "\u001b[0m\n",
      "> \u001b[0;32m/home/aiarhipov/mmdetection/mmdet/models/dense_heads/cycle_centernet_head.py\u001b[0m(280)\u001b[0;36mget_targets\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    278 \u001b[0;31m                \u001b[0mctx_int\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcty_int\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mwidth_ratio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mheight_ratio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    279 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 280 \u001b[0;31m                gen_gaussian_target(\n",
      "\u001b[0m\u001b[0;32m    281 \u001b[0;31m                    \u001b[0mheatmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcenter_heatmap_target\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    282 \u001b[0;31m                    \u001b[0mcenter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mctx_int\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcty_int\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "102.25\n",
      "32.0\n",
      "409.9555555555555\n",
      "102.48888888888888\n",
      "102\n"
     ]
    }
   ],
   "source": [
    "%debug\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mmdet.models.utils import gaussian_radius\n",
    "radius = gaussian_radius([512/4/8, 512/4/8], min_overlap=0.3)\n",
    "radius = max(0, int(radius))\n",
    "radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2\n",
      "1 3\n"
     ]
    }
   ],
   "source": [
    "# Creating a set using string\n",
    "test_set = set()\n",
    "test_set.add((1, 2))\n",
    "test_set.add((1, 3))\n",
    "# Iterating using for loop\n",
    "for x, y in test_set:\n",
    "\tprint(x, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/home/aiarhipov/miniconda3/envs/mmdet_edit/lib/python3.8/selectors.py\u001b[0m(415)\u001b[0;36mselect\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    413 \u001b[0;31m        \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    414 \u001b[0;31m        \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 415 \u001b[0;31m            \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    416 \u001b[0;31m        \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    417 \u001b[0;31m            \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "5000\n",
      "> \u001b[0;32m/home/aiarhipov/miniconda3/envs/mmdet_edit/lib/python3.8/multiprocessing/connection.py\u001b[0m(931)\u001b[0;36mwait\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    929 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    930 \u001b[0;31m            \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 931 \u001b[0;31m                \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    932 \u001b[0;31m                \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    933 \u001b[0;31m                    \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "4.999996660975739\n",
      "> \u001b[0;32m/home/aiarhipov/miniconda3/envs/mmdet_edit/lib/python3.8/multiprocessing/connection.py\u001b[0m(424)\u001b[0;36m_poll\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    422 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    423 \u001b[0;31m    \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 424 \u001b[0;31m        \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    425 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    426 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "> \u001b[0;32m/home/aiarhipov/miniconda3/envs/mmdet_edit/lib/python3.8/multiprocessing/connection.py\u001b[0m(257)\u001b[0;36mpoll\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    255 \u001b[0;31m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    256 \u001b[0;31m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 257 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    258 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    259 \u001b[0;31m    \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "> \u001b[0;32m/home/aiarhipov/miniconda3/envs/mmdet_edit/lib/python3.8/multiprocessing/queues.py\u001b[0m(107)\u001b[0;36mget\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    105 \u001b[0;31m                \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    106 \u001b[0;31m                    \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 107 \u001b[0;31m                    \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    108 \u001b[0;31m                        \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    109 \u001b[0;31m                \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "> \u001b[0;32m/home/aiarhipov/miniconda3/envs/mmdet_edit/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m(986)\u001b[0;36m_try_get_data\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    984 \u001b[0;31m        \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    985 \u001b[0;31m        \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 986 \u001b[0;31m            \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    987 \u001b[0;31m            \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    988 \u001b[0;31m        \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "*** _queue.Empty\n",
      "<multiprocessing.queues.Queue object at 0x7f5883439ca0>\n",
      "*** _queue.Empty\n",
      "5.0\n",
      "> \u001b[0;32m/home/aiarhipov/miniconda3/envs/mmdet_edit/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m(1148)\u001b[0;36m_get_data\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m   1146 \u001b[0;31m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1147 \u001b[0;31m            \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m-> 1148 \u001b[0;31m                \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1149 \u001b[0;31m                \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1150 \u001b[0;31m                    \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "(False, None)\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "hw = torch.zeros((3, 2, 15, 9))\n",
    "c2v = torch.ones((3, 8, 10, 10)) * 4\n",
    "v2c = torch.ones((3, 8, 300, 400)) * (-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0032, 0.0273, 0.0561, 0.0273, 0.0032, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0273, 0.2369, 0.4868, 0.2369, 0.0273, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0561, 0.4868, 1.0000, 0.4868, 0.0561, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0273, 0.2369, 0.4868, 0.2369, 0.0273, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0032, 0.0273, 0.0561, 0.0273, 0.0032, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mmdet.models.utils import gaussian_radius, gen_gaussian_target\n",
    "from mmdet.models.utils.gaussian_target import get_local_maximum, get_topk_from_heatmap, transpose_and_gather_feat\n",
    "\n",
    "gen_gaussian_target(\n",
    "                    heatmap=hw[0, 0],\n",
    "                    center=[5, 5],\n",
    "                    radius=2,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0032, 0.0273, 0.0561, 0.0273, 0.0032, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0273, 0.2369, 0.4868, 0.2369, 0.0273, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0561, 0.4868, 1.0000, 0.4868, 0.0561, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0273, 0.2369, 0.4868, 0.2369, 0.0273, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0032, 0.0273, 0.0561, 0.0273, 0.0032, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hw[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "if hw[0, 0, 5, 5] == 1.:\n",
    "    print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0032, 0.0273, 0.0561, 0.0273, 0.0032, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0273, 0.2369, 0.4868, 0.2369, 0.0273, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0561, 0.4868, 1.0000, 0.4868, 0.0561, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0273, 0.2369, 0.4868, 0.2369, 0.0273, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0032, 0.0273, 0.0561, 0.0273, 0.0032, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_gaussian_target(\n",
    "                    heatmap=hw[0, 0],\n",
    "                    center=[5, 5],\n",
    "                    radius=2,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m c2v[\u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\u001b[39m-\u001b[39mtorch\u001b[39m.\u001b[39mexp(np\u001b[39m.\u001b[39mpi\u001b[39m*\u001b[39m\u001b[39mmin\u001b[39m(c2v[\u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m], torch\u001b[39m.\u001b[39mtensor(\u001b[39m1.\u001b[39m)))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "c2v[0, 0, 0, 0] += 1-torch.exp(np.pi*min(c2v[0, 0, 0, 0], torch.tensor(1.)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [4., 4., 4., 4., 4., 4., 4., 4., 4., 4.],\n",
       "        [4., 4., 4., 4., 4., 4., 4., 4., 4., 4.],\n",
       "        [4., 4., 4., 4., 4., 4., 4., 4., 4., 4.],\n",
       "        [4., 4., 4., 4., 4., 4., 4., 4., 4., 4.],\n",
       "        [4., 4., 4., 4., 4., 4., 4., 4., 4., 4.],\n",
       "        [4., 4., 4., 4., 4., 4., 4., 4., 4., 4.]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c2v[0, 0, ] = 1\n",
    "c2v[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(False)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c2v[0, 0, 0, 0] < 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfor\u001b[39;00m idx,  a ,b \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(((\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m), (\u001b[39m3\u001b[39m, \u001b[39m4\u001b[39m))):\n\u001b[1;32m      3\u001b[0m     \u001b[39mprint\u001b[39m(idx, a ,b)\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"
     ]
    }
   ],
   "source": [
    "for idx,  a ,b in enumerate(((1, 2), (3, 4))):\n",
    "    \n",
    "    print(idx, a ,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7., 7.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c2v[0, 0:2, 0, 0]- v2c[0, 0:2, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(54.5981)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.exp(c2v[0, 0, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9.8995)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(c2v[0, 0:2, 0, 0]- v2c[0, 0:2, 0, 0], p=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "hw[:, 0, ...] = (- diff[:, 0, ...] + diff[:, 2, ...] + diff[:, 4, ...] - diff[:, 6, ...]) /2\n",
    "hw[:, 1, ...] = (- diff[:, 1, ...] - diff[:, 3, ...] + diff[:, 5, ...] - diff[:, 7, ...]) /2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch' has no attribute 'expit'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m t \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrandn((\u001b[39m4\u001b[39m, \u001b[39m3\u001b[39m))\n\u001b[0;32m----> 3\u001b[0m torch\u001b[39m.\u001b[39;49mexpit(t)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch' has no attribute 'expit'"
     ]
    }
   ],
   "source": [
    "t = torch.randn((4, 3))\n",
    "\n",
    "torch.expit(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33marchiealexarkhipov\u001b[0m (\u001b[33mcenternet\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=12.65s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=3.72s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-07 20:42:07,275 - mmdet - INFO - Automatic scaling of learning rate (LR) has been disabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=4.67s)\n",
      "creating index...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-07 20:42:12,440 - mmdet - INFO - Start running, host: aiarhipov@lorien.atp-fivt.org, work_dir: /home/aiarhipov/centernet/exps/20_cycle_l1_avg_factor_8_2heatmaps_short\n",
      "2023-05-07 20:42:12,442 - mmdet - INFO - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      "(VERY_LOW    ) TensorboardLoggerHook              \n",
      "(VERY_LOW    ) MMDetWandbHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(NORMAL      ) NumClassCheckHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      "(VERY_LOW    ) TensorboardLoggerHook              \n",
      "(VERY_LOW    ) MMDetWandbHook                     \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) EvalHook                           \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(ABOVE_NORMAL) OptimizerHook                      \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      "(VERY_LOW    ) TensorboardLoggerHook              \n",
      "(VERY_LOW    ) MMDetWandbHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      "(VERY_LOW    ) TensorboardLoggerHook              \n",
      "(VERY_LOW    ) MMDetWandbHook                     \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) NumClassCheckHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      "(VERY_LOW    ) TensorboardLoggerHook              \n",
      "(VERY_LOW    ) MMDetWandbHook                     \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      "(VERY_LOW    ) TensorboardLoggerHook              \n",
      "(VERY_LOW    ) MMDetWandbHook                     \n",
      " -------------------- \n",
      "after_run:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      "(VERY_LOW    ) TensorboardLoggerHook              \n",
      "(VERY_LOW    ) MMDetWandbHook                     \n",
      " -------------------- \n",
      "2023-05-07 20:42:12,444 - mmdet - INFO - workflow: [('train', 1), ('val', 1)], max: 150 epochs\n",
      "2023-05-07 20:42:12,445 - mmdet - INFO - Checkpoints will be saved to /home/aiarhipov/centernet/exps/20_cycle_l1_avg_factor_8_2heatmaps_short by HardDiskBackend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index created!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/aiarhipov/centernet/wandb/run-20230507_204212-2prqppbh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/centernet/CenterNet/runs/2prqppbh\" target=\"_blank\">20_cycle_l1_avg_factor_8_2heatmaps_short</a></strong> to <a href=\"https://wandb.ai/centernet/CenterNet\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-07 20:42:17,584 - mmdet - WARNING - No meta information found in the runner. \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   32 of 32 files downloaded.  \n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "2023-05-07 20:51:13,915 - mmdet - INFO - Epoch [1][500/1372]\tlr: 6.244e-04, eta: 2 days, 11:38:09, time: 1.046, data_time: 0.016, memory: 2448, loss_center_heatmap: 8.7718, loss_offset: 0.1174, loss_c2v: 3.4393, loss_v2c: 0.0227, loss: 12.3512, grad_norm: 72.8073\n",
      "2023-05-07 21:00:13,240 - mmdet - INFO - Epoch [1][1000/1372]\tlr: 1.249e-03, eta: 2 days, 12:25:36, time: 1.079, data_time: 0.010, memory: 2448, loss_center_heatmap: 1.9584, loss_offset: 0.0864, loss_c2v: 1.9862, loss_v2c: 0.0162, loss: 4.0472, grad_norm: 17.3755\n",
      "2023-05-07 21:07:04,958 - mmdet - INFO - Saving checkpoint at 1 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>] 3611/3611, 10.5 task/s, elapsed: 344s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-07 21:18:05,805 - mmdet - INFO - Evaluating bbox...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=45.13s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 30\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[39m# Create work_dir\u001b[39;00m\n\u001b[1;32m     29\u001b[0m mmcv\u001b[39m.\u001b[39mmkdir_or_exist(osp\u001b[39m.\u001b[39mabspath(cfg\u001b[39m.\u001b[39mwork_dir))\n\u001b[0;32m---> 30\u001b[0m train_detector(model, datasets, cfg, distributed\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, validate\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/mmdetection/mmdet/apis/train.py:244\u001b[0m, in \u001b[0;36mtrain_detector\u001b[0;34m(model, dataset, cfg, distributed, validate, timestamp, meta)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[39melif\u001b[39;00m cfg\u001b[39m.\u001b[39mload_from:\n\u001b[1;32m    243\u001b[0m     runner\u001b[39m.\u001b[39mload_checkpoint(cfg\u001b[39m.\u001b[39mload_from)\n\u001b[0;32m--> 244\u001b[0m runner\u001b[39m.\u001b[39;49mrun(data_loaders, cfg\u001b[39m.\u001b[39;49mworkflow)\n",
      "File \u001b[0;32m~/miniconda3/envs/mmdet_edit/lib/python3.8/site-packages/mmcv/runner/epoch_based_runner.py:136\u001b[0m, in \u001b[0;36mEpochBasedRunner.run\u001b[0;34m(self, data_loaders, workflow, max_epochs, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[39mif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepoch \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_max_epochs:\n\u001b[1;32m    135\u001b[0m                 \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m--> 136\u001b[0m             epoch_runner(data_loaders[i], \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    138\u001b[0m time\u001b[39m.\u001b[39msleep(\u001b[39m1\u001b[39m)  \u001b[39m# wait for some hooks like loggers to finish\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcall_hook(\u001b[39m'\u001b[39m\u001b[39mafter_run\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/mmdet_edit/lib/python3.8/site-packages/mmcv/runner/epoch_based_runner.py:58\u001b[0m, in \u001b[0;36mEpochBasedRunner.train\u001b[0;34m(self, data_loader, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_batch\n\u001b[1;32m     56\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iter \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m---> 58\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcall_hook(\u001b[39m'\u001b[39;49m\u001b[39mafter_train_epoch\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     59\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_epoch \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/mmdet_edit/lib/python3.8/site-packages/mmcv/runner/base_runner.py:317\u001b[0m, in \u001b[0;36mBaseRunner.call_hook\u001b[0;34m(self, fn_name)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[39m\"\"\"Call all hooks.\u001b[39;00m\n\u001b[1;32m    311\u001b[0m \n\u001b[1;32m    312\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m    313\u001b[0m \u001b[39m    fn_name (str): The function name in each hook to be called, such as\u001b[39;00m\n\u001b[1;32m    314\u001b[0m \u001b[39m        \"before_train_epoch\".\u001b[39;00m\n\u001b[1;32m    315\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    316\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_hooks:\n\u001b[0;32m--> 317\u001b[0m     \u001b[39mgetattr\u001b[39;49m(hook, fn_name)(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/mmdet_edit/lib/python3.8/site-packages/mmcv/runner/hooks/evaluation.py:271\u001b[0m, in \u001b[0;36mEvalHook.after_train_epoch\u001b[0;34m(self, runner)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[39m\"\"\"Called after every training epoch to evaluate the results.\"\"\"\u001b[39;00m\n\u001b[1;32m    270\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mby_epoch \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_evaluate(runner):\n\u001b[0;32m--> 271\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_evaluate(runner)\n",
      "File \u001b[0;32m~/mmdetection/mmdet/core/evaluation/eval_hooks.py:63\u001b[0m, in \u001b[0;36mEvalHook._do_evaluate\u001b[0;34m(self, runner)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlatest_results \u001b[39m=\u001b[39m results\n\u001b[1;32m     62\u001b[0m runner\u001b[39m.\u001b[39mlog_buffer\u001b[39m.\u001b[39moutput[\u001b[39m'\u001b[39m\u001b[39meval_iter_num\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataloader)\n\u001b[0;32m---> 63\u001b[0m key_score \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mevaluate(runner, results)\n\u001b[1;32m     64\u001b[0m \u001b[39m# the key_score may be `None` so it needs to skip the action to save\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[39m# the best checkpoint\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave_best \u001b[39mand\u001b[39;00m key_score:\n",
      "File \u001b[0;32m~/miniconda3/envs/mmdet_edit/lib/python3.8/site-packages/mmcv/runner/hooks/evaluation.py:367\u001b[0m, in \u001b[0;36mEvalHook.evaluate\u001b[0;34m(self, runner, results)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mevaluate\u001b[39m(\u001b[39mself\u001b[39m, runner, results):\n\u001b[1;32m    361\u001b[0m     \u001b[39m\"\"\"Evaluate the results.\u001b[39;00m\n\u001b[1;32m    362\u001b[0m \n\u001b[1;32m    363\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[39m        runner (:obj:`mmcv.Runner`): The underlined training runner.\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \u001b[39m        results (list): Output results.\u001b[39;00m\n\u001b[1;32m    366\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 367\u001b[0m     eval_res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataloader\u001b[39m.\u001b[39;49mdataset\u001b[39m.\u001b[39;49mevaluate(\n\u001b[1;32m    368\u001b[0m         results, logger\u001b[39m=\u001b[39;49mrunner\u001b[39m.\u001b[39;49mlogger, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meval_kwargs)\n\u001b[1;32m    370\u001b[0m     \u001b[39mfor\u001b[39;00m name, val \u001b[39min\u001b[39;00m eval_res\u001b[39m.\u001b[39mitems():\n\u001b[1;32m    371\u001b[0m         runner\u001b[39m.\u001b[39mlog_buffer\u001b[39m.\u001b[39moutput[name] \u001b[39m=\u001b[39m val\n",
      "File \u001b[0;32m~/mmdetection/mmdet/datasets/coco.py:642\u001b[0m, in \u001b[0;36mCocoDataset.evaluate\u001b[0;34m(self, results, metric, logger, jsonfile_prefix, classwise, proposal_nums, iou_thrs, metric_items)\u001b[0m\n\u001b[1;32m    639\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcat_ids \u001b[39m=\u001b[39m coco_gt\u001b[39m.\u001b[39mget_cat_ids(cat_names\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mCLASSES)\n\u001b[1;32m    641\u001b[0m result_files, tmp_dir \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mformat_results(results, jsonfile_prefix)\n\u001b[0;32m--> 642\u001b[0m eval_results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mevaluate_det_segm(results, result_files, coco_gt,\n\u001b[1;32m    643\u001b[0m                                       metrics, logger, classwise,\n\u001b[1;32m    644\u001b[0m                                       proposal_nums, iou_thrs,\n\u001b[1;32m    645\u001b[0m                                       metric_items)\n\u001b[1;32m    647\u001b[0m \u001b[39mif\u001b[39;00m tmp_dir \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    648\u001b[0m     tmp_dir\u001b[39m.\u001b[39mcleanup()\n",
      "File \u001b[0;32m~/mmdetection/mmdet/datasets/coco.py:531\u001b[0m, in \u001b[0;36mCocoDataset.evaluate_det_segm\u001b[0;34m(self, results, result_files, coco_gt, metrics, logger, classwise, proposal_nums, iou_thrs, metric_items)\u001b[0m\n\u001b[1;32m    529\u001b[0m         eval_results[item] \u001b[39m=\u001b[39m val\n\u001b[1;32m    530\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 531\u001b[0m     cocoEval\u001b[39m.\u001b[39;49mevaluate()\n\u001b[1;32m    532\u001b[0m     cocoEval\u001b[39m.\u001b[39maccumulate()\n\u001b[1;32m    534\u001b[0m     \u001b[39m# Save coco summarize print information to logger\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/mmdet_edit/lib/python3.8/site-packages/pycocotools/cocoeval.py:154\u001b[0m, in \u001b[0;36mCOCOeval.evaluate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    152\u001b[0m evaluateImg \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mevaluateImg\n\u001b[1;32m    153\u001b[0m maxDet \u001b[39m=\u001b[39m p\u001b[39m.\u001b[39mmaxDets[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m--> 154\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mevalImgs \u001b[39m=\u001b[39m [evaluateImg(imgId, catId, areaRng, maxDet)\n\u001b[1;32m    155\u001b[0m          \u001b[39mfor\u001b[39;00m catId \u001b[39min\u001b[39;00m catIds\n\u001b[1;32m    156\u001b[0m          \u001b[39mfor\u001b[39;00m areaRng \u001b[39min\u001b[39;00m p\u001b[39m.\u001b[39mareaRng\n\u001b[1;32m    157\u001b[0m          \u001b[39mfor\u001b[39;00m imgId \u001b[39min\u001b[39;00m p\u001b[39m.\u001b[39mimgIds\n\u001b[1;32m    158\u001b[0m      ]\n\u001b[1;32m    159\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_paramsEval \u001b[39m=\u001b[39m copy\u001b[39m.\u001b[39mdeepcopy(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparams)\n\u001b[1;32m    160\u001b[0m toc \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n",
      "File \u001b[0;32m~/miniconda3/envs/mmdet_edit/lib/python3.8/site-packages/pycocotools/cocoeval.py:154\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    152\u001b[0m evaluateImg \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mevaluateImg\n\u001b[1;32m    153\u001b[0m maxDet \u001b[39m=\u001b[39m p\u001b[39m.\u001b[39mmaxDets[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m--> 154\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mevalImgs \u001b[39m=\u001b[39m [evaluateImg(imgId, catId, areaRng, maxDet)\n\u001b[1;32m    155\u001b[0m          \u001b[39mfor\u001b[39;00m catId \u001b[39min\u001b[39;00m catIds\n\u001b[1;32m    156\u001b[0m          \u001b[39mfor\u001b[39;00m areaRng \u001b[39min\u001b[39;00m p\u001b[39m.\u001b[39mareaRng\n\u001b[1;32m    157\u001b[0m          \u001b[39mfor\u001b[39;00m imgId \u001b[39min\u001b[39;00m p\u001b[39m.\u001b[39mimgIds\n\u001b[1;32m    158\u001b[0m      ]\n\u001b[1;32m    159\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_paramsEval \u001b[39m=\u001b[39m copy\u001b[39m.\u001b[39mdeepcopy(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparams)\n\u001b[1;32m    160\u001b[0m toc \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n",
      "File \u001b[0;32m~/miniconda3/envs/mmdet_edit/lib/python3.8/site-packages/pycocotools/cocoeval.py:280\u001b[0m, in \u001b[0;36mCOCOeval.evaluateImg\u001b[0;34m(self, imgId, catId, aRng, maxDet)\u001b[0m\n\u001b[1;32m    277\u001b[0m m   \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m    278\u001b[0m \u001b[39mfor\u001b[39;00m gind, g \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(gt):\n\u001b[1;32m    279\u001b[0m     \u001b[39m# if this gt already matched, and not a crowd, continue\u001b[39;00m\n\u001b[0;32m--> 280\u001b[0m     \u001b[39mif\u001b[39;00m gtm[tind,gind]\u001b[39m>\u001b[39m\u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m iscrowd[gind]:\n\u001b[1;32m    281\u001b[0m         \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m    282\u001b[0m     \u001b[39m# if dt matched to reg gt, and on ignore gt, stop\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os.path as osp\n",
    "from sys import argv\n",
    "\n",
    "import mmcv\n",
    "import wandb\n",
    "from mmcv import Config\n",
    "from mmdet.apis import set_random_seed, train_detector\n",
    "\n",
    "# Let's take a look at the dataset image\n",
    "from mmdet.datasets import build_dataset\n",
    "from mmdet.models import build_detector\n",
    "\n",
    "wandb.login()\n",
    "\n",
    "cfg = Config.fromfile(f\"/home/aiarhipov/centernet/exps/20_cycle_l1/config.py\")\n",
    "\n",
    "\n",
    "set_random_seed(0, deterministic=False)\n",
    "\n",
    "# Build dataset\n",
    "datasets = [build_dataset(cfg.data.train), build_dataset(cfg.data.val_loss)]\n",
    "\n",
    "# Build the detector\n",
    "model = build_detector(cfg.model)\n",
    "# Add an attribute for visualization convenience\n",
    "model.CLASSES = datasets[0].CLASSES\n",
    "\n",
    "# Create work_dir\n",
    "mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n",
    "train_detector(model, datasets, cfg, distributed=False, validate=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 2\n",
    "y = 3\n",
    "x, y = map(lambda x: 5 if x > 5 else x if x > 0 else 0, (x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2, 3, 1, 2, 3)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1, 2, 3)* 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=55.42s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "import os.path as osp\n",
    "from sys import argv\n",
    "\n",
    "import mmcv\n",
    "import wandb\n",
    "from mmcv import Config\n",
    "from mmdet.apis import set_random_seed, train_detector\n",
    "\n",
    "# Let's take a look at the dataset image\n",
    "from mmdet.datasets import build_dataset\n",
    "from mmdet.models import build_detector\n",
    "import subprocess\n",
    "import random\n",
    "\n",
    "\n",
    "def get_free_gpu():\n",
    "    log = str(\n",
    "        subprocess.check_output(\"nvidia-smi --format=csv --query-gpu=utilization.gpu,memory.used\", shell=True)\n",
    "    ).split(r\"\\n\")[1:-1]\n",
    "    free_gpu = []\n",
    "    for idx, gpu_info in enumerate(log):\n",
    "        if gpu_info[:-4].split(\" %, \")[0] == \"0\" and gpu_info[:-4].split(\" %, \")[1] == \"3\":\n",
    "            free_gpu.append(idx)\n",
    "    if free_gpu:\n",
    "        return random.choice(free_gpu)\n",
    "    raise RuntimeError(\"All gpus are used\")\n",
    "\n",
    "cfg = Config.fromfile(f\"/home/aiarhipov/centernet/exps/25_test_ds/config.py\")\n",
    "\n",
    "\n",
    "set_random_seed(0, deterministic=False)\n",
    "cfg.gpu_ids = [get_free_gpu()]\n",
    "val = True\n",
    "# Build dataset\n",
    "\n",
    "datasets = build_dataset(cfg.data.train)\n",
    "# datasets = [build_dataset(cfg.data.train), build_dataset(cfg.data.val_loss)]\n",
    "# # Build the detector\n",
    "# model = build_detector(cfg.model)\n",
    "# # Add an attribute for visualization convenience\n",
    "# model.CLASSES = datasets[0].CLASSES\n",
    "\n",
    "# # Create work_dir\n",
    "# mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n",
    "# train_detector(model, datasets, cfg, distributed=False, validate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['img_metas', 'img', 'gt_bboxes', 'gt_labels'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataContainer({'filename': '/home/aiarhipov/datasets/WTW-dataset/train/images/20200211180812076257-0.jpg', 'ori_filename': '20200211180812076257-0.jpg', 'ori_shape': (2132, 1500, 3), 'img_shape': (512, 512, 3), 'pad_shape': (512, 512, 3), 'scale_factor': array([1.1130434, 1.1130434, 1.1130434, 1.1130434], dtype=float32), 'flip': False, 'flip_direction': None, 'img_norm_cfg': {'mean': array([103.53 , 116.28 , 123.675], dtype=float32), 'std': array([1., 1., 1.], dtype=float32), 'to_rgb': False}})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[0][\"img_metas\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets[0][\"gt_bboxes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataContainer(PolygonMasks(num_masks=39, height=512, width=360))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[0][\"gt_masks\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiarhipov/mmdetection/mmdet/utils/setup_env.py:38: UserWarning: Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.\n",
      "  warnings.warn(\n",
      "/home/aiarhipov/mmdetection/mmdet/utils/setup_env.py:48: UserWarning: Setting MKL_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=3.96s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-26 04:19:07,134 - root - INFO - ModulatedDeformConvPack neck.deconv_layers.0.conv is upgraded to version 2.\n",
      "2023-05-26 04:19:07,137 - root - INFO - ModulatedDeformConvPack neck.deconv_layers.2.conv is upgraded to version 2.\n",
      "2023-05-26 04:19:07,139 - root - INFO - ModulatedDeformConvPack neck.deconv_layers.4.conv is upgraded to version 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint from local path: /home/aiarhipov/centernet/exps/24_long/latest.pth\n",
      "[                                ] 6/3611, 0.8 task/s, elapsed: 7s, ETA:  4289s"
     ]
    }
   ],
   "source": [
    "# Copyright (c) OpenMMLab. All rights reserved.\n",
    "import argparse\n",
    "import os\n",
    "import os.path as osp\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import mmcv\n",
    "import torch\n",
    "from mmcv import Config, DictAction\n",
    "from mmcv.cnn import fuse_conv_bn\n",
    "from mmcv.runner import (get_dist_info, init_dist, load_checkpoint,\n",
    "                         wrap_fp16_model)\n",
    "\n",
    "from mmdet.apis import multi_gpu_test, single_gpu_test\n",
    "from mmdet.datasets import (build_dataloader, build_dataset,\n",
    "                            replace_ImageToTensor)\n",
    "from mmdet.models import build_detector\n",
    "from mmdet.utils import (build_ddp, build_dp, compat_cfg, get_device,\n",
    "                         replace_cfg_vals, setup_multi_processes,\n",
    "                         update_data_root)\n",
    "cfg = Config.fromfile(\"/home/aiarhipov/centernet/exps/24_long/config.py\")\n",
    "\n",
    "# replace the ${key} with the value of cfg.key\n",
    "cfg = replace_cfg_vals(cfg)\n",
    "\n",
    "# update data root according to MMDET_DATASETS\n",
    "update_data_root(cfg)\n",
    "\n",
    "cfg = compat_cfg(cfg)\n",
    "\n",
    "# set multi-process settings\n",
    "setup_multi_processes(cfg)\n",
    "\n",
    "# set cudnn_benchmark\n",
    "if cfg.get('cudnn_benchmark', False):\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "if 'pretrained' in cfg.model:\n",
    "    cfg.model.pretrained = None\n",
    "elif 'init_cfg' in cfg.model.backbone:\n",
    "    cfg.model.backbone.init_cfg = None\n",
    "\n",
    "if cfg.model.get('neck'):\n",
    "    if isinstance(cfg.model.neck, list):\n",
    "        for neck_cfg in cfg.model.neck:\n",
    "            if neck_cfg.get('rfp_backbone'):\n",
    "                if neck_cfg.rfp_backbone.get('pretrained'):\n",
    "                    neck_cfg.rfp_backbone.pretrained = None\n",
    "    elif cfg.model.neck.get('rfp_backbone'):\n",
    "        if cfg.model.neck.rfp_backbone.get('pretrained'):\n",
    "            cfg.model.neck.rfp_backbone.pretrained = None\n",
    "\n",
    "\n",
    "cfg.gpu_ids = [7]\n",
    "\n",
    "cfg.device = get_device()\n",
    "# init distributed env first, since logger depends on the dist info.\n",
    "\n",
    "distributed = False\n",
    "\n",
    "\n",
    "test_dataloader_default_args = dict(\n",
    "    samples_per_gpu=1, workers_per_gpu=2, dist=distributed, shuffle=False)\n",
    "\n",
    "# in case the test dataset is concatenated\n",
    "if isinstance(cfg.data.test, dict):\n",
    "    cfg.data.test.test_mode = True\n",
    "    if cfg.data.test_dataloader.get('samples_per_gpu', 1) > 1:\n",
    "        # Replace 'ImageToTensor' to 'DefaultFormatBundle'\n",
    "        cfg.data.test.pipeline = replace_ImageToTensor(\n",
    "            cfg.data.test.pipeline)\n",
    "elif isinstance(cfg.data.test, list):\n",
    "    for ds_cfg in cfg.data.test:\n",
    "        ds_cfg.test_mode = True\n",
    "    if cfg.data.test_dataloader.get('samples_per_gpu', 1) > 1:\n",
    "        for ds_cfg in cfg.data.test:\n",
    "            ds_cfg.pipeline = replace_ImageToTensor(ds_cfg.pipeline)\n",
    "\n",
    "test_loader_cfg = {\n",
    "    **test_dataloader_default_args,\n",
    "    **cfg.data.get('test_dataloader', {})\n",
    "}\n",
    "\n",
    "rank, _ = get_dist_info()\n",
    "# allows not to create\n",
    "\n",
    "# build the dataloader\n",
    "dataset = build_dataset(cfg.data.test)\n",
    "data_loader = build_dataloader(dataset, **test_loader_cfg)\n",
    "\n",
    "# build the model and load checkpoint\n",
    "cfg.model.train_cfg = None\n",
    "model = build_detector(cfg.model, test_cfg=cfg.get('test_cfg'))\n",
    "fp16_cfg = cfg.get('fp16', None)\n",
    "if fp16_cfg is not None:\n",
    "    wrap_fp16_model(model)\n",
    "checkpoint = load_checkpoint(model, \"/home/aiarhipov/centernet/exps/24_long/latest.pth\", map_location='cpu')\n",
    "\n",
    "# old versions did not save class info in checkpoints, this walkaround is\n",
    "# for backward compatibility\n",
    "if 'CLASSES' in checkpoint.get('meta', {}):\n",
    "    model.CLASSES = checkpoint['meta']['CLASSES']\n",
    "else:\n",
    "    model.CLASSES = dataset.CLASSES\n",
    "\n",
    "if not distributed:\n",
    "    model = build_dp(model, cfg.device, device_ids=cfg.gpu_ids)\n",
    "    outputs = single_gpu_test(model, data_loader, False, \"/home/aiarhipov/centernet/exps/24_long\",\n",
    "                                0.3)\n",
    "else:\n",
    "    model = build_ddp(\n",
    "        model,\n",
    "        cfg.device,\n",
    "        device_ids=[int(os.environ['LOCAL_RANK'])],\n",
    "        broadcast_buffers=False)\n",
    "    outputs = multi_gpu_test(\n",
    "        model, data_loader, \"/home/aiarhipov/centernet/exps/24_long\", True\n",
    "        or cfg.evaluation.get('gpu_collect', False))\n",
    "\n",
    "rank, _ = get_dist_info()\n",
    "if rank == 0:\n",
    "    if True:\n",
    "        print(f'\\nwriting results to {\"/home/aiarhipov/centernet/exps/24_long/test_output.pkl\"}')\n",
    "        mmcv.dump(outputs, \"/home/aiarhipov/centernet/exps/24_long/test_output.pkl\")\n",
    "    kwargs = {} \n",
    "\n",
    "    if True:\n",
    "        eval_kwargs = cfg.get('evaluation', {}).copy()\n",
    "        # hard-code way to remove EvalHook args\n",
    "        for key in [\n",
    "                'interval', 'tmpdir', 'start', 'gpu_collect', 'save_best',\n",
    "                'rule', 'dynamic_intervals'\n",
    "        ]:\n",
    "            eval_kwargs.pop(key, None)\n",
    "        eval_kwargs.update(dict(metric=\"bbox\", **kwargs))\n",
    "        metric = dataset.evaluate(outputs, **eval_kwargs)\n",
    "        print(metric)\n",
    "        metric_dict = dict(config=args.config, metric=metric)\n",
    "        if args.work_dir is not None and rank == 0:\n",
    "            mmcv.dump(metric_dict, json_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmdet_edit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
