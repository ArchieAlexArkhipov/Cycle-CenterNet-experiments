{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "from utils import *\n",
    "import mmcv\n",
    "import torch\n",
    "import wandb\n",
    "from mmcv import Config\n",
    "from mmcv.parallel import MMDistributedDataParallel\n",
    "from mmdet.apis import set_random_seed, train_detector\n",
    "from mmdet.apis import init_detector, inference_detector, show_result_pyplot\n",
    "from algo2_result_to_aligned_result import algo2_result_to_aligned_result\n",
    "# Let's take a look at the dataset image\n",
    "from mmdet.datasets import build_dataset\n",
    "from mmdet.models import build_detector\n",
    "from xml_to_np import xml_to_np\n",
    "from AP import calc_iou_individual, get_single_image_results\n",
    "from soft_nms import py_cpu_softnms\n",
    "from dbscan_result_to_aligned_result import dbscan_result_to_aligned_result\n",
    "from AP import calc_iou_individual\n",
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "from utils import print_LC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=3.83s)\n",
      "creating index...\n",
      "index created!\n",
      "load checkpoint from local path: /home/aiarhipov/centernet/exps/16_paper_params_dla34_batch8/epoch_150.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-03 12:38:41,057 - root - INFO - ModulatedDeformConvPack neck.deconv_layers.0.conv is upgraded to version 2.\n",
      "2023-05-03 12:38:41,145 - root - INFO - ModulatedDeformConvPack neck.deconv_layers.2.conv is upgraded to version 2.\n",
      "2023-05-03 12:38:41,237 - root - INFO - ModulatedDeformConvPack neck.deconv_layers.4.conv is upgraded to version 2.\n"
     ]
    }
   ],
   "source": [
    "checkpoint_file = '/home/aiarhipov/centernet/exps/16_paper_params_dla34_batch8/epoch_150.pth'\n",
    "\n",
    "config_file = \"/home/aiarhipov/centernet/exps/16_paper_params_dla34_batch8/config.py\"\n",
    "cfg = Config.fromfile(config_file)\n",
    "\n",
    "set_random_seed(0, deterministic=False)\n",
    "\n",
    "dataset = build_dataset(cfg.data.test)\n",
    "\n",
    "model = build_detector(cfg.model)\n",
    "model.CLASSES = dataset.CLASSES\n",
    "\n",
    "model = init_detector(config_file, checkpoint_file, device='cuda:6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(92, 4)\n",
      "(87, 4)\n"
     ]
    }
   ],
   "source": [
    "conf_threshold = 0.5\n",
    "iou_threshold = 0.9\n",
    "res = []\n",
    "# for idx in tqdm(range(int(len(dataset)))):\n",
    "idx = 7\n",
    "anno = dataset.get_ann_info(idx=idx)\n",
    "boxes = anno[\"bboxes\"]\n",
    "segm_path = anno[\"seg_map\"]\n",
    "xml_path = f\"/home/aiarhipov/datasets/WTW-dataset/test/xml/{segm_path[:-4]}.xml\"\n",
    "img_path = f\"/home/aiarhipov/datasets/WTW-dataset/test/images/{segm_path[:-4]}.jpg\"\n",
    "\n",
    "gt_boxes = xml_to_np(xml_path)\n",
    "# print(f\"gt_boxes[0] = {gt_boxes[:5]}\")\n",
    "pred = inference_detector(model, img_path)[0]\n",
    "# print(f\"pred[0] = {pred[:5]}\")\n",
    "conf_indexes = py_cpu_softnms(pred[:, :4], pred[:, 4], thresh=0.475, method=2)\n",
    "# print(f\"conf_indexes = {conf_indexes}\")\n",
    "conf_pred = pred[conf_indexes]\n",
    "# print(f\"conf_pred[0] = {conf_pred[:5]}\")\n",
    "if conf_pred.shape[0] > 1:\n",
    "    conf_pred = dbscan_result_to_aligned_result([conf_pred])\n",
    "    if conf_pred:\n",
    "        conf_pred = conf_pred[0]\n",
    "        print(gt_boxes[:, :4].shape)\n",
    "        print(conf_pred[:, :4].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_result_pyplot(model, img_path, [conf_pred[:, :4]], score_thr = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LC_for_dbscan_algo(pred):\n",
    "    res = np.pad(pred, ((0,0),(0,4)), mode=\"constant\", constant_values=np.nan)\n",
    "    # left_edge.append(((box[0], box[1]), (box[0], box[3])))\n",
    "    # right_edge.append(((box[2], box[1]), (box[2], box[3])))\n",
    "    # up_edge.append(((box[0], box[1]), (box[2], box[1])))\n",
    "    # down_edge.append(((box[0], box[3]), (box[2], box[3])))\n",
    "    x = np.unique(np.hstack((pred[:, 0], pred[:, 2])))\n",
    "    y = np.unique(np.hstack((pred[:, 1], pred[:, 3])))\n",
    "    for idx, box in enumerate(pred):\n",
    "        startrow = np.where(np.isclose(y, box[1]))[0][0]\n",
    "        endrow = np.where(np.isclose(y, box[3]))[0][0] - 1\n",
    "        startcolumn = np.where(np.isclose(x, box[0]))[0][0]\n",
    "        endcolumn = np.where(np.isclose(x, box[2]))[0][0] - 1\n",
    "        res[idx, -1] = endcolumn\n",
    "        res[idx, -2] = startcolumn\n",
    "        res[idx, -3] = endrow\n",
    "        res[idx, -4] = startrow\n",
    "    return res\n",
    "    \n",
    "# print_LC(img_path, LC_for_dbscan_algo(conf_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_pred = LC_for_dbscan_algo(conf_pred)\n",
    "matched_gt = np.insert(gt_boxes, 4, np.nan, axis=1)\n",
    "for idx, g in enumerate(gt_boxes):\n",
    "    iou = pd.Series([calc_iou_individual(p[:4], g[:4]) for p in conf_pred])\n",
    "    max_idx = iou.argmax()\n",
    "    max_idx = max_idx if iou[max_idx] > iou_threshold else np.nan\n",
    "    matched_gt[idx, 4] = max_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_LC(img_path, np.insert(conf_pred, 9, range(conf_pred.shape[0]), axis=1), out_path=\"example_with_bounding_boxes_pred.jpg\")\n",
    "print_LC(img_path, np.insert(matched_gt, 9, range(matched_gt.shape[0]), axis=1), out_path=\"example_with_bounding_boxes_gt.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot convert float NaN to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 38\u001b[0m\n\u001b[1;32m     36\u001b[0m                     tp \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m     37\u001b[0m     \u001b[39mreturn\u001b[39;00m tp\n\u001b[0;32m---> 38\u001b[0m adjacency_relation_per_image_dbscan(gt_boxes, conf_pred, iou_threshold\u001b[39m=\u001b[39;49m\u001b[39m0.5\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[8], line 23\u001b[0m, in \u001b[0;36madjacency_relation_per_image_dbscan\u001b[0;34m(gt, pred, iou_threshold)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39mfor\u001b[39;00m idx, g \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(matched_gt):\n\u001b[1;32m     22\u001b[0m     \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39misnan(g[\u001b[39m4\u001b[39m]):\n\u001b[0;32m---> 23\u001b[0m         anchor_pred_idx \u001b[39m=\u001b[39m \u001b[39mint\u001b[39;49m(g[\u001b[39m4\u001b[39;49m])\n\u001b[1;32m     24\u001b[0m         gt_right_idx,  \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mwhere((matched_gt[:,\u001b[39m7\u001b[39m] \u001b[39m==\u001b[39m g[\u001b[39m8\u001b[39m]\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m&\u001b[39m (matched_gt[:,\u001b[39m5\u001b[39m] \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m g[\u001b[39m5\u001b[39m]) \u001b[39m&\u001b[39m (matched_gt[:,\u001b[39m6\u001b[39m] \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m g[\u001b[39m5\u001b[39m]))\n\u001b[1;32m     25\u001b[0m         gt_down_idx, \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mwhere((matched_gt[:,\u001b[39m5\u001b[39m] \u001b[39m==\u001b[39m g[\u001b[39m6\u001b[39m]\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m&\u001b[39m (matched_gt[:,\u001b[39m7\u001b[39m] \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m g[\u001b[39m7\u001b[39m]) \u001b[39m&\u001b[39m (matched_gt[:,\u001b[39m8\u001b[39m] \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m g[\u001b[39m7\u001b[39m]))\n",
      "\u001b[0;31mValueError\u001b[0m: cannot convert float NaN to integer"
     ]
    }
   ],
   "source": [
    "def adjacency_relation_per_image_dbscan(gt, pred, iou_threshold=0) -> dict:\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    gt : shape(n, 4) xmin, ymin, xmax, ymax, [match], startrow, endrow, startcol, endcol\n",
    "    gt : shape(n, 4)   0 ,  1  ,  2  ,   3 ,    4   ,     5   ,    6  ,     7   ,   8\n",
    "        \n",
    "    pred : shape(n, 5) xmin, ymin, xmax, ymax, confidence, [startrow, endrow, startcol, endcol]\n",
    "    pred : shape(n, 5)   0 ,  1  ,  2  ,   3 ,       4   ,     5    ,    6  ,     7   ,   8\n",
    "        \n",
    "    \"\"\"\n",
    "    pred = LC_for_dbscan_algo(pred)\n",
    "    matched_gt = np.insert(gt, 4, np.nan, axis=1)\n",
    "    for idx, g in enumerate(gt):\n",
    "        iou = pd.Series([calc_iou_individual(p[:4], g[:4]) for p in pred])\n",
    "        max_idx = iou.argmax()\n",
    "        max_idx = max_idx if iou[max_idx] > iou_threshold else np.nan\n",
    "        matched_gt[idx, 4] = max_idx\n",
    "    \n",
    "    for idx, g in enumerate(matched_gt):\n",
    "        if np.isnan(g[4]):\n",
    "            anchor_pred_idx = int(g[4])\n",
    "            gt_right_idx,  = np.where((matched_gt[:,7] == g[8]+1) & (matched_gt[:,5] <= g[5]) & (matched_gt[:,6] >= g[5]))\n",
    "            gt_down_idx, = np.where((matched_gt[:,5] == g[6]+1) & (matched_gt[:,7] <= g[7]) & (matched_gt[:,8] >= g[7]))\n",
    "            if gt_right_idx:\n",
    "                gt_right_idx = gt_right_idx[0]\n",
    "                pred_right_idx, = np.where((pred[:,7] == pred[anchor_pred_idx, 8] + 1) & (pred[:,5] == g[5]))\n",
    "                if (pred[pred_right_idx, :4] == matched_gt[gt_right_idx, :4]).all():\n",
    "                    tp +=1\n",
    "\n",
    "            if gt_down_idx:\n",
    "                gt_down_idx = gt_down_idx[0]\n",
    "                pred_down_idx, = np.where((pred[:,5] == pred[anchor_pred_idx, 6] + 1) & (pred[:,7] == g[7]))\n",
    "                if (pred[pred_down_idx, :4] == matched_gt[gt_down_idx, :4]).all():\n",
    "                    tp +=1\n",
    "    return tp\n",
    "adjacency_relation_per_image_dbscan(gt_boxes, conf_pred, iou_threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6,  7,  8],\n",
       "       [ 9, 10, 11],\n",
       "       [12, 13, 14]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[ 0,  1,  2],\n",
    "       [ 3,  4,  5],\n",
    "       [ 6,  7,  8],\n",
    "       [ 9, 10, 11],\n",
    "       [12, 13, 14]])\n",
    "a[np.where(a[:, 2] > 5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmdet_edit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
